{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness, context_utilization, noise_sensitivity_relevant\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "def determine_metrics(user_query, assistant_response, context, ground_truth):\n",
    "    metrics = []\n",
    "\n",
    "    # Check conditions and append appropriate metrics\n",
    "    if user_query is not None and assistant_response is not None and context is not None:\n",
    "        metrics.append(faithfulness)\n",
    "        metrics.append(answer_relevancy)\n",
    "        metrics.append(context_utilization) #precision @k\n",
    "\n",
    "    if user_query is not None and assistant_response is not None and context is not None and ground_truth is not None:\n",
    "        # metrics.append(context_precision)\n",
    "        metrics.append(context_recall)\n",
    "        # metrics.append(noise_sensitivity_relevant)\n",
    "\n",
    "    if user_query is not None and assistant_response is not None and ground_truth is not None:\n",
    "        metrics.append(answer_similarity)\n",
    "        metrics.append(answer_correctness)\n",
    "\n",
    "    if context is not None and ground_truth is not None:\n",
    "        metrics.append(context_entity_recall)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def std_evaluate(user_query=None, assistant_response=None, context=None, ground_truth=None):\n",
    "    # Initialize the dictionary\n",
    "    data = {}\n",
    "\n",
    "    # Add key-value pairs to the dictionary if the corresponding variables are not None\n",
    "    if user_query is not None:\n",
    "        data['question'] = [user_query]\n",
    "\n",
    "    if assistant_response is not None:\n",
    "        data['answer'] = [assistant_response]\n",
    "\n",
    "    if context is not None:\n",
    "        data['contexts'] = [context]\n",
    "\n",
    "    if ground_truth is not None:\n",
    "        data['ground_truth'] = [ground_truth]\n",
    "    metrics = determine_metrics(user_query, assistant_response, context, ground_truth)\n",
    "    \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    score = evaluate(dataset,metrics=metrics)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f78b4bf0194a3b99da433077b9d764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.5000, 'answer_relevancy': 0.9767, 'context_utilization': 0.5000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"What is the weather today?\"\n",
    "assistant_response = \"The weather today is CLOUDY (5°C)\"\n",
    "context = [\"The user asked about today's weather.\", \"weather is CLOUDY\", \"temprature is 25°C.\"]\n",
    "ground_truth = \"The weather forecast for today is sunny with a high of 25°C.\"\n",
    "std_evaluate(user_query = user_query, assistant_response= assistant_response, ground_truth=None, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faithfulness, answer_relevancy,  context_utilization      -> user_query, assistent_response, context\n",
    "# context_precision     -> user_query, assistent_response, context, ground_truth\n",
    "# answer_similarity, answer_correctness -> user_query, assistent_response, ground_truth\n",
    "# context_entity_recall                 -> context, ground_truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
